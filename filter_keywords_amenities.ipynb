{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "from spacy import displacy\n",
    "from spacy.matcher import Matcher, PhraseMatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep = ['id','ask', 'bedrooms', 'numRooms', 'title','original_title',\n",
    "'latitude','longitude','zip_muni','studio','one_bedroom','two_bedroom', 'three_bedroom', \n",
    "'four_bedroom','five_bedroom','six_bedroom','seven_bedroom','eight_bedroom',\n",
    "'periodblt', 'roomrent', 'sublet','shortterm', 'shared']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.read_csv('listings_unique_NOT-FULL_2018_20191028.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_full[keep].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only Craiglist\n",
    "df_a = df.iloc[15196:139214]\n",
    "df_b = df.iloc[147617:273821]\n",
    "df_c = df.iloc[284924:405947]\n",
    "df_d = df.iloc[408712:]\n",
    "df = pd.concat([df_a,df_b,df_c,df_d])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PhaseMatcher - Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling list of keywords from different data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = pd.read_excel('Cambridge_listings_2018_flagged.xlsx', sheet_name='Auto-Skip Phrases')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = words['ROOM AVAILABLE IN'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_2 = pd.read_excel('FullListings_2018_Misclassifications (002).xlsx', sheet_name='keywords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extarct keywords from the ones previously used\n",
    "\n",
    "words_mis_camb = []\n",
    "\n",
    "words_c1 = words_2['roomrent'].tolist()\n",
    "words_c2 = words_2['sublet'][:3].tolist()\n",
    "words_c3 = words_2['shortterm'][:1].tolist()\n",
    "words_c4 = words_2['shared'][:3].tolist()\n",
    "\n",
    "all_words = [words_c1,words_c2,words_c3,words_c4]\n",
    "\n",
    "for w in all_words:\n",
    "    words_mis_camb = words_mis_camb+w\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cleaning keywords\n",
    "words_mis_camb[3] = 'ONE ROOM IN'\n",
    "words_mis_camb[4] = 'ONE BEDROOM IN'\n",
    "words_mis_camb[5] = 'ONE BEDROOM AVAILABLE IN'\n",
    "words_mis_camb[12] = 'ROOMS AVAILABLE IN'\n",
    "words_mis_camb[15] = 'ROOM IN'\n",
    "words_mis_camb[21] = 'BEDROOMS AVAILABLE IN'\n",
    "words_mis_camb[23] = 'BEDROOMS OPEN IN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words2 = pd.DataFrame(words_mis_camb, columns=['words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a bool series from isin() \n",
    "isnotindf = words2[~words2[\"words\"].isin(words)]\n",
    "isnotindf = isnotindf['words'].tolist()\n",
    "phrase_list = isnotindf + words\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completed compiling list of keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ROOM RENT',\n",
       " 'ROOMMATE',\n",
       " 'ROOMIE',\n",
       " 'ONE ROOM IN',\n",
       " 'ONE BEDROOM IN',\n",
       " 'ROOM AVAILABLE IN',\n",
       " 'ONE BEDROOM IN',\n",
       " 'ONE ROOM IN',\n",
       " 'ROOMMATES NEEDED',\n",
       " 'ROOM IN',\n",
       " 'ROOM IN',\n",
       " 'SUBLET',\n",
       " 'SHORT TERM',\n",
       " 'SHARED',\n",
       " 'SHARE',\n",
       " 'ONE BEDROOM AVAILABLE IN',\n",
       " 'PRIVATE ROOM',\n",
       " 'ONE ROOM AVAILABLE',\n",
       " 'FURNISHED BEDROOM',\n",
       " 'APARTMENT SHARING',\n",
       " 'ROOMS AVAILABLE IN',\n",
       " 'ROOMMATES',\n",
       " 'PRIVATE BEDROOM',\n",
       " 'RENTING ROOM',\n",
       " 'MASTER BEDROOM IN',\n",
       " 'BEDROOMS AVAILABLE IN',\n",
       " 'ONE BEDROOM OPEN IN',\n",
       " 'BEDROOMS OPEN IN',\n",
       " 'SUBLEASING',\n",
       " 'SUBLEASE']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Current list of keywords\n",
    "phrase_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_listing(dataframe):\n",
    "    \n",
    "    '''\n",
    "    Input Parameters: 1) pandas dataframe from which the index \n",
    "                         and title will be extracted \n",
    "                      2) keywords as a list - already compiled a list for reference\n",
    "                      \n",
    "    Output: Returns 1) index of flaggled listing\n",
    "                    2) Keyword found in listing\n",
    "    '''\n",
    "    #Spacy Phraser Object\n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    \n",
    "    #convert each phrase to a Doc object:\n",
    "    phrase_patterns = [nlp(text) for text in phrase_list]\n",
    "\n",
    "    # Pass each Doc object into matcher (note the use of the asterisk!):\n",
    "    matcher.add('Cambridge_keywords', None, *phrase_patterns)\n",
    "    \n",
    "    all_matches = []\n",
    "    idx_matches = []\n",
    "\n",
    "    # Looping through dataset and instantiating Spacy docuemnt\n",
    "    for x in dataframe.itertuples():\n",
    "        title = (x.title)\n",
    "        idx = x.Index\n",
    "        title = nlp(title)\n",
    "        matches = matcher(title)\n",
    "\n",
    "        #For title object, finding the keywords\n",
    "        for match_id, start, end in matches:\n",
    "            string_id = nlp.vocab.strings[match_id]  \n",
    "            #span = keyword that was matched on\n",
    "            span = title[start:end]  \n",
    "\n",
    "            #Index that should be dropped - flagged\n",
    "            idx_matches.append(idx)\n",
    "            #Keyword that was flagged for that listing\n",
    "            all_matches.append(span.text)\n",
    "            \n",
    "    return idx_matches, all_matches  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity Recognition : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_excel('FullListings_2018_Misclassifications (002).xlsx', sheet_name='Flagging_misclassifications')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x , y = filter_listing(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ROOM IN'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sample = df.sample(frac= 0.0005)\n",
    "\n",
    "for title in sample['title'].values:\n",
    "    title = nlp(title)\n",
    "    for ent in title.ents:\n",
    "        if ent.label_ != 'CARDINAL':\n",
    "            print(f'{ent.text:{50}} {ent.start_char:{2}} {ent.end_char:{2}} {ent.label_:{1}} {spacy.explain(ent.label_)}')\n",
    "            #displacy.render(sentence,style='ent', jupyter=True)''\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan of Action for Entity Recognition/Amentities: \n",
    "### keywords would be better to locate custom entities and find variation in location & price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
