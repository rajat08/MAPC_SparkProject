{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import en_core_web_sm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "types = {'id':'str', 'ask':'str', 'bedrooms':'int', 'numRooms':'int', 'title':'str', 'original_title':'str',\n",
    "      'muni_ID':'str', 'muni':'str',\n",
    "       'zip_muni':'str', 'uniqueid':'str', \n",
    "       'bos_yr_built':'str', 'flagged': 'int'}\n",
    "\n",
    "listings = pd.read_csv(\"FullListings_2018_Misclassifications_flagged.csv\", delimiter= \",\", dtype = types)\n",
    "\n",
    "\n",
    "list_reduced = listings[['id', 'ask', 'bedrooms', 'numRooms', 'title', 'original_title', 'muni',\n",
    "       'zip_muni', 'uniqueid', 'flagged']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "\n",
    "# Load English tokenizer, with stopwords\n",
    "parser = English()\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "#FOR POS TAGGING\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "#TESTING POS TAGGING\n",
    "\n",
    "# docs = nlp(str(list_reduced.original_title[1]))\n",
    "\n",
    "# for word in docs:\n",
    "#     print(word.text,word.pos_)\n",
    "\n",
    "def spacy_tagger(sentence):\n",
    "    #removing stop words\n",
    "#     mytokens = parser(sentence)\n",
    "#     print(mytokens)\n",
    "#     mytokens = [word for word in sentence if word not in stop_words and word not in punctuations ]\n",
    "    #creating a pos tagger for the titles, \n",
    "    mytokens = nlp(str(sentence))\n",
    "    \n",
    "    \n",
    "    for mytokens\n",
    "    # return preprocessed list of tokens, and the pos tag for the tokens\n",
    "    list1 = []\n",
    "    for word in mytokens:\n",
    "        list1.append(word.text +\" \" + word.pos_)\n",
    "    \n",
    "        \n",
    "    return list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"one\"\n",
    "b = \"thirty\"\n",
    "s<b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulramesh/anaconda3/envs/MAPC/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "#checking the number of rooms\n",
    "def spacy_num(sentence):\n",
    "    #removing stop words\n",
    "#     mytokens = parser(sentence)\n",
    "#     print(mytokens)\n",
    "#     mytokens = [word for word in sentence if word not in stop_words and word not in punctuations ]\n",
    "    #creating a pos tagger for the titles, \n",
    "    mytokens = nlp(str(sentence))\n",
    "    \n",
    "    \n",
    "    for x in mytokens:\n",
    "        if x.pos_ == \"ADJ\":\n",
    "    # return preprocessed list of tokens, and the pos tag for the tokens\n",
    "            return x.text\n",
    "\n",
    "list_reduced['num_format'] = list_reduced['title'].apply(spacy_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LARGE        41\n",
       "NEW          18\n",
       "PRIVATE      10\n",
       "HOT           9\n",
       "SUNNY         5\n",
       "FURNISHED     5\n",
       "CENTRAL       4\n",
       "AMAZING       4\n",
       "LOOKING       2\n",
       "BIG           2\n",
       "STUNNING      2\n",
       "PERSONAL      1\n",
       "OK            1\n",
       "FRESH         1\n",
       "RECENT        1\n",
       "LAST          1\n",
       "HARBOR        1\n",
       "BEDROOM       1\n",
       "SINGLE        1\n",
       "CLEAN         1\n",
       "NICE          1\n",
       "THIRD         1\n",
       "INCLUDED      1\n",
       "PRIME         1\n",
       "SAVE          1\n",
       "FREE          1\n",
       "CHARMING      1\n",
       "Name: num_format, dtype: int64"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_reduced['num_format'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'spacy.tokens.doc.Doc' object has no attribute 'num'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-138-3ad1bef44c6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts_of_num_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mvalidating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ONE BEDROOM IN A THREE BEDROOM HOUSE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-138-3ad1bef44c6c>\u001b[0m in \u001b[0;36mvalidating\u001b[0;34m(mytokens2)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mvalidating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmytokens2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmytokens2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmytokens2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mmytokens2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mcounts_of_num_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'spacy.tokens.doc.Doc' object has no attribute 'num'"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "validate_dict = {\"ONE\":1, \"TWO\":2, \"THREE\":3,  \"FOUR\":4, \"FIVE\":5,\"SIX\":6, \"SEVEN\":7, \"EIGHT\":8,\"NINE\":9, \"TEN\":10}\n",
    "def validating(mytokens2): \n",
    "    mytokens2 = nlp(str(mytokens2))\n",
    "    count = 0\n",
    "    counts_of_num_text = []\n",
    "    for t in mytokens2:\n",
    "        if len(counts_of_num_text)> 1:\n",
    "            if counts_of_num_text[0] <= counts_of_num_text[1]:\n",
    "                return(\"1\")\n",
    "            else:\n",
    "                \n",
    "        if t.pos_ == \"NUM\":\n",
    "            if str(t.text) in validate_dict:\n",
    "                counts_of_num_text.append(validate_dict[t.text])\n",
    "            count+=1\n",
    "\n",
    "validating(\"ONE BEDROOM IN A THREE BEDROOM HOUSE\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      "ADP\n",
      "DET\n",
      "NUM\n",
      "NOUN\n",
      "NOUN\n"
     ]
    }
   ],
   "source": [
    "myt = nlp(\"2 IN A TWO BEDROOM HOUSE\")\n",
    "list2 = []\n",
    "for x in myt:\n",
    "    print(x.pos_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TWO\n",
      "po\n"
     ]
    }
   ],
   "source": [
    "str1 = \"TWO po\"\n",
    "text = nlp(str(str1))\n",
    "for x in text:\n",
    "    print(x.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahulramesh/anaconda3/envs/MAPC/lib/python3.7/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "list_reduced['pos_tagged'] = list_reduced['original_title'].apply(spacy_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NO DET', 'FEE PROPN', 'Great ADJ', 'location NOUN', '- PUNCT', 'betw ADJ', 'Central PROPN', '+ SYM', 'Inman PROPN', 'Square PROPN', '- PUNCT', '1 NUM', 'bed NOUN', 'available ADJ']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Cambridge PROPN',\n",
       " 'spacious ADJ',\n",
       " '1br/1ba NUM',\n",
       " 'in ADP',\n",
       " '2br/2ba NUM',\n",
       " 'apt ADJ',\n",
       " ', PUNCT',\n",
       " 'no DET',\n",
       " 'fee NOUN',\n",
       " ', PUNCT',\n",
       " 'available ADJ',\n",
       " 'now ADV',\n",
       " '! PUNCT']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doesn't do well example\n",
    "print(list_reduced.iloc[205]['pos_tagged'])\n",
    "\n",
    "#does well on\n",
    "list_reduced.iloc[1]['pos_tagged'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
